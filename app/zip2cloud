#!/bin/sh

# Script to compress and encrypt mongodb backup directories and then sync them against a
# cloud S3 bucket
#
# Depends on 7zip and rclone
#
# sychan@lbl.gov
# 5/21/2021

# Directory containing db dumps to be archived/compressed/copied
DUMP_BASE=/dump/

# Directory to put the zipped backups
ZIP_DIR=/zip/

NOW=$(/bin/date +"%Y%m%d%H%M")

# Name of the zip'ed db backup. The .7z extension wil be added by the 7zip program

ZIP_BASE=backup_full_
ZIP_NAME=${ZIP_BASE}${NOW}

[ -r /run/secrets/encryption_key ] || { echo "Encryption key not readable in /run/secrets/encryption_key" ; exit 1; }
[ -r /run/secrets/gcp_backup_creds ] || { echo "Google cloud service credentials not found in /run/secrets/gcp_back_creds" ; exit 1; }
[ -z "${BUCKET}" ] && { echo "S3 bucketname not set in BUCKET environment variable" ; exit 1; }
[ -z "${BUCKETPATH}" ] && { echo "Path within S3 bucket not set in BUCKETPATH environment variable" ; exit 1; }
[ -z "${DELETE_DUMP}" ] || echo "DELETE_DUMP set, will delete files/directories under /dump/ when done compressing"

# This is the password used to generate the AES256 encryption key
SECRET=`cat /run/secrets/encryption_key`

# This is the Google Cloud Storage path, note that it depends on rclone being preconfigured
# for "remote" using the runtime creds, check rclone config in /root/.config/rclone/rclone.conf
REMOTE=remote:${BUCKET}/${BUCKETPATH}

# Delete any files older than 30 days in the zip directory
echo "Deleting database archives older than 30 days"
/usr/bin/find ${ZIP_DIR} -mtime +30 -type f -name "${ZIP_BASE}*" -print -exec rm {} \;

echo "Zipping ${DUMP_BASE}/${DUMP_DIR} to ${ZIP_DIR}/${ZIP_NAME}"
cd /
/usr/bin/7za a -p${SECRET} ${ZIP_DIR}/${ZIP_NAME}  -mx=7 -mhe -t7z ${DUMP_BASE} || { echo "Could not zip ${DUMP_BASE} into ${ZIP_DIR}/${ZIP_NAME}" ; exit 1; }
[ -z "${DELETE_DUMP}" ] || { echo "Clearing contents of /dump/"; cd /dump/; rm -rf *; }

echo "RClone-ing ${ZIP_DIR} to GCP ${GCP_DEST}"
/bin/rclone sync ${ZIP_DIR}/ ${REMOTE}

